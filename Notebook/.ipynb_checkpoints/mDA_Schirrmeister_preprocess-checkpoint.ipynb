{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic import\n",
    "import numpy as np\n",
    "import itertools as iter\n",
    "import os\n",
    "\n",
    "# mne import\n",
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.io import concatenate_raws\n",
    "from mne.io.edf import read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne import set_log_level\n",
    "\n",
    "set_log_level(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as iter\n",
    "import scipy as sc\n",
    "import pickle as pk\n",
    "\n",
    "# mne import\n",
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.io import concatenate_raws\n",
    "from mne.io.edf import read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne import set_log_level\n",
    "\n",
    "# pyriemann import\n",
    "import pyriemann\n",
    "from pyriemann.classification import MDM, TSclassifier, class_distinctiveness\n",
    "from pyriemann.estimation import Covariances, Coherences\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.embedding import SpectralEmbedding\n",
    "from pyriemann.transfer import encode_domains, decode_domains, TLCenter, TLStretch, TLRotate\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.clustering import Kmeans\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, TimeSeriesSplit, BaseCrossValidator\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import itertools\n",
    "\n",
    "set_log_level(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/cameronboruto/.local/lib/python3.8/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
      "Loading subjects [1, 2]...\n"
     ]
    }
   ],
   "source": [
    "selected_events = None\n",
    "inconsistent_session = False\n",
    "\n",
    "# ========================\n",
    "\n",
    "from moabb.datasets import Schirrmeister2017\n",
    "\n",
    "# ====================================\n",
    "# ======== Schirrmeister2017 =========\n",
    "# ====================================\n",
    "\n",
    "dataset1 = Schirrmeister2017()\n",
    "subjects = [i+1 for i in range(14)] # 14\n",
    "sessions = [\"0\"]\n",
    "runs = [\"0train\", \"1test\"]\n",
    "tmin, tmax = 1., 3.\n",
    "sample_step = 3 # chan = 128\n",
    "dispersion_1 = 50\n",
    "dispersion_2 = 1000\n",
    "dispersion_3 = 100\n",
    "\n",
    "# ====================================\n",
    "\n",
    "n_subjects = len(subjects)\n",
    "n_sessions = len(sessions)\n",
    "n_runs = len(runs)\n",
    "\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:219: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "/home/cameronboruto/.local/lib/python3.8/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
      "Loading subjects [1, 2]...\n"
     ]
    }
   ],
   "source": [
    "all_epochs = []\n",
    "all_labels = []\n",
    "\n",
    "for subject in subjects:\n",
    "    print(f\"Loading subjects {subjects}...\")\n",
    "    data = dataset1.get_data(subjects=[subject])\n",
    "\n",
    "    print(f\"Processing raw data for subject {subject}\")\n",
    "    # ========================\n",
    "    \n",
    "    raw_files = [\n",
    "        data[subject][ses][run] for ses, run in iter.product(sessions, runs)\n",
    "    ]\n",
    "    raw = concatenate_raws(raw_files)\n",
    "        \n",
    "    picks = pick_types(\n",
    "        raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "    # subsample elecs\n",
    "    picks = picks[::sample_step]\n",
    "\n",
    "    # Apply band-pass filter\n",
    "    raw.filter(7., 35., method='iir', picks=picks)\n",
    "\n",
    "    events, event_ids = mne.events_from_annotations(raw, event_id = selected_events)\n",
    "\n",
    "    # Reannotation\n",
    "    # Get the annotations\n",
    "    annotations = raw.annotations.copy()\n",
    "\n",
    "    # Loop through annotations to find trial onsets\n",
    "    for idx, annot in enumerate(raw.annotations):  # Iterate until the second to last annotation\n",
    "        # Create a new annotation for resting-state\n",
    "        if selected_events:\n",
    "            if raw.annotations[idx]['description'] not in selected_events:\n",
    "                continue\n",
    "        if raw.annotations[idx]['duration'] > 0:\n",
    "            duration = raw.annotations[idx]['duration']\n",
    "            duration = max(1, duration)\n",
    "            onset = annot['onset'] - duration\n",
    "            description = 'idle'\n",
    "\n",
    "            # Add this resting-state period as a new annotation\n",
    "            annotations.append(onset, duration, description)\n",
    "\n",
    "    # Update the annotations in the raw data\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    # Extract events including resting-state periods\n",
    "    if selected_events:\n",
    "        events, event_ids = mne.events_from_annotations(raw)\n",
    "        selected_events['idle'] = event_ids['idle']\n",
    "    events, event_ids = mne.events_from_annotations(raw, event_id = selected_events)\n",
    "    \n",
    "    # ========================\n",
    "\n",
    "    # Read epochs (train will be done only between 1 and 2s)\n",
    "    # Testing will be done with a running classifier\n",
    "    epochs = Epochs(\n",
    "        raw,\n",
    "        events,\n",
    "        None,\n",
    "        tmin,\n",
    "        tmax,\n",
    "        proj=True,\n",
    "        picks=picks,\n",
    "        baseline=None,\n",
    "        preload=True,\n",
    "        verbose=False)\n",
    "    labels = epochs.events[:, -1]\n",
    "\n",
    "    print(\"Shape of events: \", events.shape[0])\n",
    "    print(\"Shape of labels: \", labels.shape[0])\n",
    "    \n",
    "    all_epochs.append(epochs)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "    os.rmdir(\"~/mne_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './epoch_data' already exists.\n",
      "Save epoched data to epoch_data. Execute mDA_Schirrmeister.ipynb to show the analysis.\n"
     ]
    }
   ],
   "source": [
    "epoch_path = \"../epoch_data\"\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(epoch_path):\n",
    "    # If it doesn't exist, create the directory\n",
    "    os.mkdir(epoch_path)\n",
    "    print(f\"Directory '{epoch_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{epoch_path}' already exists.\")\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    with open(f\"{epoch_path}/sch_{sub}_epoch.pkl\", 'wb') as f:\n",
    "        pk.dump(all_epochs[i], f)\n",
    "    with open(f\"{epoch_path}/sch_{sub}_label.pkl\", 'wb') as f:\n",
    "        pk.dump(all_labels[i], f)\n",
    "\n",
    "print(\"Save epoched data to epoch_data. Execute mDA_Schirrmeister.ipynb to show the analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
